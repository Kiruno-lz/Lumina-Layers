Lumina-Layers
An experimental FDM engine exploring layered optical color mixing. Starting with CMYK pixel art, evolving into a universal multi-material photo processor.

ðŸ›‘ NON-COMMERCIAL USE ONLY

This software and any models generated by it are licensed under CC BY-NC-SA 4.0.

Do NOT sell the generated STL/3MF files.

Do NOT sell physical prints generated by this tool.

Do NOT package this tool into a paid service.

For commercial licensing inquiries, please contact the author.

ðŸ“– Overview
Lumina-Layers bridges the gap between digital pixels and physical filaments.

Traditional multi-color relief tools rely on theoretical "Transmission Distance" (TD) values, which often fail due to filament batch variance, nozzle temperature, or slicer logic. Lumina-Layers uses a Closed-Loop Calibration System. By scanning a physically printed color matrix, it builds a "Ground Truth" Look-Up Table (LUT) specific to your printer hardware, ensuring accurate color reproduction for pixel art and relief models.

ðŸ”„ The Closed-Loop Workflow
The ecosystem consists of three specialized tools working in sequence:

1. The Factory: calibration_gen.py
Generates a precision calibration board to physically test filament mixing.

1024-Color Matrix: Full permutation of 4 base filaments across 5 layers (0.4mm).

Face-Down Optimization: Prints the viewing surface directly on the build plate for a smooth finish.

Solid Backing: Automatically generates a 1.6mm opaque backing (White) to ensure color consistency and structural rigidity.

Anti-Overlap Geometry: Applies 0.05mm micro-shrinkage to voxels to prevent slicer line-width conflicts.

2. The Scanner: calibration_app.py
Digitizes the physical reality of your printer.

Computer Vision: Auto-aligns the grid using perspective warp and lens distortion correction.

Digital Twin: Extracts RGB values from the print and generates a .npy LUT file.

Human-in-the-Loop: Interactive probe tools allow you to manually verify and correct specific color block readings (e.g., removing glare/shadows).

3. The Engine: app.py
Converts images into printable 3D models using the calibrated data.

Smart Palette: Uses K-Means++ to extract key colors from the input image.

Physical Mapping: Maps image pixels to the actual printable colors found in your LUT.

Split Printing: Exports High-Res color layers (0.08mm) and Low-Res backing (0.2mm) as separate objects for print speed optimization.

ðŸ—ºï¸ Development Roadmap
Phase 1: The Foundation (Current) âœ…
Target: Pixel Art & Simple Graphics.

Logic: Fixed CMYW (Cyan, Magenta, Yellow, White) mixing.

Tech: Integer-based "Slab" geometry; Solid Backing generation.

Status: Stable.

Phase 2: Manga Mode (Monochrome) ðŸš§
Target: Manga panels, Ink drawings, High-contrast illustrations.

Logic: Black & White layering using thickness-based grayscale (Lithophane logic).

Tech: Simulating screen tones (Ben-Day dots).

Phase 3: Full-Color Photo Engine
Target: Photographs, Anime illustrations.

Logic: Dynamic Palette Support (4/6/8 colors).

Tech:

Advanced Dithering algorithms (Floyd-Steinberg/Atkinson) to simulate gradients.

LAB Color Space integration for better perceptual matching.

Phase 4: Web 3D Preview
Target: WYSIWYG (What You See Is What You Get).

Tech: Real-time WebGL/Three.js rendering to visualize transmission effects before printing.

ðŸ› ï¸ Installation
Clone the repository

Bash

git clone https://github.com/YourUsername/Lumina-Layers.git
cd Lumina-Layers
Install dependencies

Bash

pip install -r requirements.txt
ðŸš€ Usage Guide
Step 1: Build the Reference
Run the generator to create your test print file.

Bash

python calibration_gen.py
Output: A .3mf file.

Print Settings: Global layer height 0.08mm. Backing plate can be set to 0.2mm.

Filaments: Slot 1=White, 2=Red, 3=Yellow, 4=Blue (or your custom set).

Step 2: Calibrate
Take a photo of your print (Face-up) and run the calibration tool.

Bash

python calibration_app.py
Action: Upload photo -> Align corners -> Adjust distortion sliders -> Download my_printer_lut.npy.

Step 3: Generate
Run the main engine with your calibration data.

Bash

python app.py
Action: Upload .npy file + Your Image -> Extract Palette -> Generate Model.

ðŸ§± Technical Stack
Core Logic: Python (NumPy for voxel manipulation)

Geometry Engine: Trimesh (Boolean & Export)

UI Framework: Gradio

Vision Stack: OpenCV (Perspective & Color Extraction)

ðŸ“„ License
This project is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0).

Attribution: You must give appropriate credit.

NonCommercial: You may not use this for commercial purposes.

ShareAlike: If you modify it, you must distribute it under the same license
